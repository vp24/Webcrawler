# Webcrawler

Webcrawler to find all the links in a domain
#
npm run start (website)

The webcrawler takes in an a url as input and then lists all the links relative to the website's domain. The shortcoming of the crawler is the time it would take to go through a large website with many subdomains. In the case that https://github.com is entered as an input, the crawler will attempt to list every link associated with github including every user and their repositories. The project can be improved by making a frontend for easier user interface and visuals, and by having way to sort and search for specific urls. It can also be improved to look for a specific element or word instead of just URLS.
